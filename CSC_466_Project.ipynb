{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CSC 466 Project.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "yXbAyVCU8o-K",
        "ciV2vsVCWZjP",
        "YE9VvxWxJ0pj",
        "inrl6WIjJkad",
        "Ycu8fZJHLWHz",
        "wvJx9jHau7oq",
        "MRz7b5LsaHaF",
        "bMQj7G21hMX8",
        "IkP9YgWIGtUl",
        "9Pkl1V1aHd7f",
        "dHH-mup7H5-W",
        "Qq3HkqlVJd5_",
        "OfqwjvljJDhB",
        "LHD4GKydhQ-y",
        "T5m2JInLhEM1",
        "C6gN03ePhIWb",
        "Dyhkrl-xvBQo"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ddb0be00470e43de8f2e72e005f117b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4f263d0290d74435b3df03d36cb5cd45",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "",
            "max": 20,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 20,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_41ab5397e23c42f9afb6b466f4898020"
          }
        },
        "4f263d0290d74435b3df03d36cb5cd45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "41ab5397e23c42f9afb6b466f4898020": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sfnesbit/CSC466-Team13/blob/main/CSC_466_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yB7RM2Et89Qc"
      },
      "source": [
        "# 466 Team 13 Food Image Classification\n",
        "Ty Farris | Marine Cossoul | Sean Nesbit\n",
        "\n",
        "[Multiclass image classification article](https://towardsdatascience.com/end-to-end-pipeline-for-setting-up-multiclass-image-classification-for-data-scientists-2e051081d41c)\n",
        "\n",
        "[Also](https://medium.com/swlh/convolutional-neural-networks-for-multiclass-image-classification-a-beginners-guide-to-6dbc09fabbd)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXbAyVCU8o-K"
      },
      "source": [
        "##  Mount drive\n",
        "*You may need to visit CSC466 folder, and 'Add Shortcut to Drive' or 'Move To > My Drive\"*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnsPwlnc6YNK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d06cd74-564c-4b0c-d15c-0a367d2fa32d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "datadir = \"drive/MyDrive/CSC466/csc466_data/\"\n",
        "testdir = datadir+'images_test/'\n",
        "traindir = datadir+'images_train/'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIbEf0f5m9ds",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2b7e2d0-1c70-4a95-946b-060e25578470"
      },
      "source": [
        "#Test that you can see into the directory\n",
        "!ls drive/MyDrive/CSC466/csc466_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "datagenerator\t\t grayscale_model_40epochs.h5  images_npy    meta\n",
            "first_model_40epochs.h5  grayscale_model_60epochs.h5  images_test   X.txt\n",
            "first_model.h5\t\t grayscale_model_80epochs.h5  images_train  y.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ciV2vsVCWZjP"
      },
      "source": [
        "# OLD ATTEMPT: Create train and test datasets\n",
        "These code cells are from our previous attempts when we would build a numpy file in our drive which would hold the preprocessed data.\n",
        "\n",
        "This is no longer used in our final result, but is left for viewing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YE9VvxWxJ0pj"
      },
      "source": [
        "### Create Training .npy files\n",
        "Preprocess the images and build .npy files for each class found"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_8Uq8djPzKN"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from ipywidgets import IntProgress\n",
        "from IPython.display import display\n",
        "import cv2 as cv\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "image_train_path = datadir+\"images_train\"\n",
        "x_train = []\n",
        "y_train = []\n",
        "\n",
        "dirsRead = 0\n",
        "totalFilesFound = 0\n",
        "numClasses = 20\n",
        "\n",
        "#list all the directories\n",
        "directories=[d for d in os.listdir(image_train_path) if os.path.isdir(image_train_path+'/'+d)]\n",
        "\n",
        "#iterate over each directory, preprocess each file and save into class.npy file\n",
        "for dir in directories:\n",
        "  dirsRead += 1\n",
        "  filesRead = 0\n",
        "  print(\"directory: {} | {}\".format(dirsRead, dir))\n",
        "  f = IntProgress(min=0, max=1000) # instantiate the bar\n",
        "  display(f) # display the bar\n",
        "\n",
        "  if dirsRead > numClasses: #collect only n classes\n",
        "    break\n",
        "\n",
        "  dir_path = image_train_path + \"/\" + dir\n",
        "  for file in os.listdir(dir_path):\n",
        "    f.value += 1 # signal to increment the progress bar\n",
        "    filesRead += 1\n",
        "    #read in the image\n",
        "    imagePath = image_train_path + \"/\" + dir + \"/\" + file\n",
        "    image = cv.imread(imagePath)\n",
        "\n",
        "    #resize the image to 128x128\n",
        "    image = cv.resize(image, (128, 128)) \n",
        "\n",
        "    #add the image and corresponding label to x_train and y_train\n",
        "    x_train.append(image)\n",
        "    y_train.append(dir)\n",
        "    totalFilesFound += 1\n",
        "\n",
        "  #save results to a file\n",
        "  x_train = np.array(x_train, dtype=\"float\") / 255.0\n",
        "  np.save(datadir+'images_npy' + f\"/x_{dir}.npy\", x_train)\n",
        "  y_train = np.array(y_train)\n",
        "  np.save(datadir+'images_npy' + f\"/y_{dir}.npy\", y_train)\n",
        "  print(f'Writing file: {dir} | Found {filesRead} images, {len(x_train)} elements')\n",
        "  #reset arrays\n",
        "  filesRead = 0\n",
        "  x_train = []\n",
        "  y_train = []\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inrl6WIjJkad"
      },
      "source": [
        "# OLD ATTEMPT: Load Train/Test data from saved .npy files\n",
        "Read each numpy file into *x* and *y* variable to be shuffled and split in subsequent cells "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ycu8fZJHLWHz"
      },
      "source": [
        "## Load x,y into RAM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTZ87LLjJyHo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "ddb0be00470e43de8f2e72e005f117b5",
            "4f263d0290d74435b3df03d36cb5cd45",
            "41ab5397e23c42f9afb6b466f4898020"
          ]
        },
        "outputId": "a094cfad-4952-40e8-b898-829ced7772db"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from ipywidgets import IntProgress\n",
        "from IPython.display import display\n",
        "\n",
        "x,y = None, None\n",
        "count = 1\n",
        "filecount = 0\n",
        "temp = None\n",
        "splitCount = 1000 #images per class to load into RAM\n",
        "numClasses = 10 #how many classes to load into RAM\n",
        "f = IntProgress(min=0, max=numClasses*2) # instantiate the progress bar\n",
        "display(f) # display the bar\n",
        "xCount = 0\n",
        "yCount = 0\n",
        "\n",
        "for file in os.listdir(datadir+'images_npy/'):\n",
        "  f.value += 1\n",
        "  #file is an X_ file (contains image data)\n",
        "  if \"x_\" in file and xCount < numClasses:\n",
        "    xCount = xCount + 1\n",
        "    temp = np.load(datadir+'images_npy/'+file)[:splitCount]\n",
        "    if x is None:\n",
        "      x = temp\n",
        "    else:\n",
        "      x = np.append(x,temp,0)\n",
        "  #file is a Y_ file (contains label)\n",
        "  elif 'y_' in file and yCount < numClasses:\n",
        "    yCount = yCount + 1\n",
        "    temp = np.load(datadir+'images_npy/'+file)[:splitCount]\n",
        "    if y is None:\n",
        "      y = temp\n",
        "    else:\n",
        "      y = np.append(y,temp, 0)\n",
        "print(len(x),len(y))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ddb0be00470e43de8f2e72e005f117b5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "IntProgress(value=0, max=20)"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "10000 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qkGIHUbfib4D"
      },
      "source": [
        "## Shuffle, Split, One-Hot Encode\n",
        "These cells will shuffle the data then split it into Training / Test / Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdyKwdNGLsOa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60016079-5d80-458e-c725-6cd4b22fc999"
      },
      "source": [
        "from sklearn.utils import shuffle\n",
        "x,y = shuffle(x,y)\n",
        "\n",
        "x_train, y_train, x_test, y_test = [],[],[],[]\n",
        "split = 0.8\n",
        "val_split = 0.9\n",
        "train_test_split_index = int(np.ceil(split*len(x)))\n",
        "test_val_split_index = int(np.ceil(val_split*len(x)))\n",
        "\n",
        "\n",
        "x_train = x[:train_test_split_index]\n",
        "y_train = y[:train_test_split_index]\n",
        "x_test  = x[train_test_split_index:test_val_split_index]\n",
        "y_test  = y[train_test_split_index:test_val_split_index]\n",
        "x_val   = x[test_val_split_index:]\n",
        "y_val   = y[test_val_split_index:]\n",
        "\n",
        "print(f'Train: ({len(x_train)}, {len(y_train)}) | Test: ({len(x_test)}, {len(y_test)}) | Val: ({len(x_val)}),({len(y_val)})')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train: (8000, 8000) | Test: (1000, 1000) | Val: (1000),(1000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MsmMCBhbUqKa"
      },
      "source": [
        "### Create label map for onehot encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCXL4D1WMimA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ebd40b7-e1b0-4c76-823a-949f4902fa86"
      },
      "source": [
        "ldict = {key: 0 for key in np.unique(y_train)}\n",
        "for item in y_train:\n",
        "  ldict[item] += 1\n",
        "\n",
        "#creates a label mapping\n",
        "labels = list(set(np.unique(y_train)).union(np.unique(y_test)))\n",
        "labels = dict([(image_label.lower().replace(\" \", \"_\"), index) for index, image_label in enumerate(labels)])\n",
        "print(labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'beef_tartare': 0, 'breakfast_burrito': 1, 'bread_pudding': 2, 'apple_pie': 3, 'beet_salad': 4, 'beignets': 5, 'beef_carpaccio': 6, 'baby_back_ribs': 7, 'bibimbap': 8, 'baklava': 9}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLnRGMnuUw_Y"
      },
      "source": [
        "## Onehot encode the values of train/test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcnmwtZsTk51"
      },
      "source": [
        "from keras.utils.np_utils import to_categorical   \n",
        "\n",
        "#one hot encoded label values\n",
        "categorical_labels = to_categorical(np.arange(len(labels)), num_classes=len(labels))\n",
        "categorical_labels\n",
        "\n",
        "y_train2 = []\n",
        "y_test2 = []\n",
        "y_val2 = []\n",
        "for i in range(len(y_train)):\n",
        "  label_index = labels[y_train[i]]\n",
        "  y_train2.append(categorical_labels[label_index])\n",
        "  \n",
        "for i in range(len(y_test)):\n",
        "  label_index = labels[y_test[i]]\n",
        "  y_test2.append(categorical_labels[label_index])\n",
        "  \n",
        "for i in range(len(y_val)):\n",
        "  label_index = labels[y_val[i]]\n",
        "  y_val2.append(categorical_labels[label_index])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wvJx9jHau7oq"
      },
      "source": [
        "# Build model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_XZ1r4YzkIM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c9b01af-a539-4422-aa2b-372a1c0e06a2"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.keras.backend.clear_session()\n",
        "num_classes = 20\n",
        "\n",
        "cnn = tf.keras.models.Sequential()\n",
        "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=(5,5), activation='relu', input_shape=[img_height, img_width, 3]))\n",
        "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=(5,5), activation='relu'))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
        "cnn.add(tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu'))\n",
        "cnn.add(tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu'))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
        "cnn.add(tf.keras.layers.Flatten())\n",
        "cnn.add(tf.keras.layers.Dense(128, activation='relu'))\n",
        "cnn.add(tf.keras.layers.Dense(num_classes, activation='softmax'))\n",
        "\n",
        "cnn.summary()\n",
        "cnn.compile(optimizer='adam', loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 60, 60, 32)        2432      \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 56, 56, 32)        25632     \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 28, 28, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 26, 26, 64)        18496     \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 24, 24, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 9216)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               1179776   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 20)                2580      \n",
            "=================================================================\n",
            "Total params: 1,265,844\n",
            "Trainable params: 1,265,844\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRz7b5LsaHaF"
      },
      "source": [
        "# ImageDataGenerator\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMQj7G21hMX8"
      },
      "source": [
        "## Build Data Generators"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IkP9YgWIGtUl"
      },
      "source": [
        "### Standard ImageDataGenerator\n",
        "sheer_range = 0.2\n",
        "\n",
        "zoom_range = 0.2\n",
        "\n",
        "horizontal_flip = True\n",
        "\n",
        "target_size = (128,128)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVxQ7451aBSf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea7a4e10-ce50-4b25-b36b-aaf5524c0099"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_data_dir = datadir + \"datagenerator\"\n",
        "img_height = 128\n",
        "img_width = 128\n",
        "batch_size = 32\n",
        "nb_epochs = 40\n",
        "\n",
        "train_datagen_standard = ImageDataGenerator(rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    validation_split=0.2) # set validation split\n",
        "\n",
        "train_generator_standard = train_datagen_standard.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='training',\n",
        "    shuffle=True) # set as training data\n",
        "\n",
        "validation_generator_standard = train_datagen_standard.flow_from_directory(\n",
        "    train_data_dir, # same directory as training data\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='validation',\n",
        "    shuffle=True) # set as validation data"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 16000 images belonging to 20 classes.\n",
            "Found 4000 images belonging to 20 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Pkl1V1aHd7f"
      },
      "source": [
        "### Rotation ImageDataGenerator\n",
        "Standard + \n",
        "\n",
        "rotation_range = 30"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8zXTHJRWHfYZ",
        "outputId": "78d040c8-55ec-4d78-c365-c0e2490d47cd"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_data_dir = datadir + \"datagenerator\"\n",
        "img_height = 128\n",
        "img_width = 128\n",
        "batch_size = 32\n",
        "nb_epochs = 40\n",
        "\n",
        "train_datagen_rotation = ImageDataGenerator(rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    rotation_range=30,\n",
        "    validation_split=0.2) # set validation split\n",
        "\n",
        "train_generator_rotation = train_datagen_rotation.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='training',\n",
        "    shuffle=True) # set as training data\n",
        "\n",
        "validation_generator_rotation = train_datagen_rotation.flow_from_directory(\n",
        "    train_data_dir, # same directory as training data\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='validation',\n",
        "    shuffle=True) # set as validation data"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 16000 images belonging to 20 classes.\n",
            "Found 4000 images belonging to 20 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHH-mup7H5-W"
      },
      "source": [
        "### Grayscale ImageDataGenerator\n",
        "Standard +\n",
        "\n",
        "colo_mode = \"grayscale\"\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8avsqsb5HtIu",
        "outputId": "c7dc6262-4860-48b1-8edc-aa4185f726f2"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_data_dir = datadir + \"datagenerator\"\n",
        "img_height = 128\n",
        "img_width = 128\n",
        "batch_size = 32\n",
        "nb_epochs = 40\n",
        "\n",
        "train_datagen_grayscale = ImageDataGenerator(rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    validation_split=0.2) # set validation split\n",
        "\n",
        "train_generator_grayscale = train_datagen_grayscale.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    color_mode=\"grayscale\",\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='training',\n",
        "    shuffle=True) # set as training data\n",
        "\n",
        "validation_generator_grayscale = train_datagen_grayscale.flow_from_directory(\n",
        "    train_data_dir, # same directory as training data\n",
        "    color_mode=\"grayscale\",\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='validation',\n",
        "    shuffle=True) # set as validation data"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 16000 images belonging to 20 classes.\n",
            "Found 4000 images belonging to 20 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qq3HkqlVJd5_"
      },
      "source": [
        "### Brightness ImageDataGenerator\n",
        "Standard + \n",
        "\n",
        "brightness_range = [0.4,1.5]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QLkKqcwsJ4V6",
        "outputId": "b67b8a50-610d-4fec-d470-5e38b514c678"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_data_dir = datadir + \"datagenerator\"\n",
        "img_height = 128\n",
        "img_width = 128\n",
        "batch_size = 32\n",
        "nb_epochs = 40\n",
        "\n",
        "train_datagen_brightness = ImageDataGenerator(rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    brightness_range=[0.4,1.5],\n",
        "    validation_split=0.2) # set validation split\n",
        "\n",
        "train_generator_brightness = train_datagen_brightness.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='training',\n",
        "    shuffle=True) # set as training data\n",
        "\n",
        "validation_generator_brightness = train_datagen_brightness.flow_from_directory(\n",
        "    train_data_dir, # same directory as training data\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='validation',\n",
        "    shuffle=True) # set as validation data"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 16000 images belonging to 20 classes.\n",
            "Found 4000 images belonging to 20 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OfqwjvljJDhB"
      },
      "source": [
        "### 64x64 ImageDataGenerator\n",
        "Standard + \n",
        "\n",
        "target_size = (64,64)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PrxD1L43JPjG",
        "outputId": "ff2b0da8-2caf-40bb-b686-d319f9f4546c"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_data_dir = datadir + \"datagenerator\"\n",
        "img_height = 64\n",
        "img_width = 64\n",
        "batch_size = 32\n",
        "nb_epochs = 40\n",
        "\n",
        "train_datagen_64x64 = ImageDataGenerator(rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    validation_split=0.2) # set validation split\n",
        "\n",
        "train_generator_64x64 = train_datagen_64x64.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(64, 64),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='training',\n",
        "    shuffle=True) # set as training data\n",
        "\n",
        "validation_generator_64x64 = train_datagen_64x64.flow_from_directory(\n",
        "    train_data_dir, # same directory as training data\n",
        "    target_size=(64, 64),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='validation',\n",
        "    shuffle=True) # set as validation data"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 16000 images belonging to 20 classes.\n",
            "Found 4000 images belonging to 20 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LHD4GKydhQ-y"
      },
      "source": [
        "## Fit the model with ImageDataGenerator\n",
        "Make sure to et ```train_generator``` and ```validation_generator``` to an appropriate generator built above"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBECHhzefWwf"
      },
      "source": [
        "nb_steps = 100\n",
        "# set generators\n",
        "train_generator = train_generator_standard\n",
        "validation_generator = validation_generator_standard\n",
        "#fit\n",
        "history = cnn.fit(\n",
        "          train_generator,\n",
        "          steps_per_epoch = nb_steps,\n",
        "          #steps_per_epoch = train_generator.samples // batch_size,\n",
        "          validation_data = validation_generator, \n",
        "          #validation_steps = validation_generator.samples // batch_size,\n",
        "          validation_steps = nb_steps,\n",
        "          epochs = nb_epochs,\n",
        "          verbose = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5m2JInLhEM1"
      },
      "source": [
        "# Save Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9arYVMQ4nALR"
      },
      "source": [
        "cnn.save_weights(datadir + \"model_40epochs_64x64images.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C6gN03ePhIWb"
      },
      "source": [
        "# Load Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_Khh0z1COwI"
      },
      "source": [
        "cnn.load_weights(datadir + \"model_40epochs_64x64images.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dyhkrl-xvBQo"
      },
      "source": [
        "# Evaluate model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUb_Hz3xvEhp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "fb80c274-9dbf-4227-e57c-31616a6efdce"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('accuracy')\n",
        "plt.title('accuracy over time')\n",
        "plt.legend(['train','val'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}